{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-Based Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision trees - simple model and model with class weight tuning\n",
    "- Bagging (bootstrap aggregation)\n",
    "- Random Forest - basic random forest and application of grid search on hyperparameter tuning\n",
    "- Boosting (AdaBoost, gradient boost, extreme gradient boost - XGBoost)\n",
    "- Ensemble of ensembles (with heterogeneous and homogeneous models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision trees can be applied to either classification or regression problems. Based on features in data, decision tree models learn a series of questions to infer the class labels of samples.\n",
    "\n",
    "![Decision Tree](DT.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminology used in decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees do not have much machinery as compared with logistic regression. Here we have a few metrics to study. We will majorly focus on impurity measures; decision trees split variables recursively based on set impurity criteria until they reach some stopping criteria (minimum observations per terminal node, minimum observations for split at any node, and so on):\n",
    "\n",
    "#### <b>Entropy</b> : \n",
    "- Entropy controls how a Decision Tree decides to split the data. It actually effects how a Decision Tree draws its boundaries.\n",
    "- Entropy came from information theory and is the measure of impurity in data. \n",
    "- If the sample is completely homogeneous, the entropy is zero, and if the sample is equally divided, it has entropy of one. \n",
    "- In decision trees, the predictor with most heterogeneousness will be considered <b>nearest to the root node</b> to classify the given data into classes in a greedy mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Entropy](entropy.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Where n = number of classes. \n",
    "- Entropy is maximum in the middle, with a value of 1 and \n",
    "- minimum at the extremes with a value of 0. \n",
    "- The low value of entropy is desirable, as it will segregate classes better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Information Gain </b> : \n",
    "\n",
    "- Information gain is the main key that is used by Decision Tree Algorithms to construct a Decision Tree.\n",
    "- Decision Trees algorithm will always tries to <b>maximize</b> Information gain.\n",
    "- An attribute with highest Information gain will tested/split first.\n",
    "- Information gain is the expected reduction in entropy caused by partitioning the examples according to a given attribute. \n",
    "- The idea is to start with mixed classes and to continue partitioning until each node reaches its observations of purest class. \n",
    "- At every stage, the variable with maximum information gain is chosen in a greedy fashion.\n",
    "- <b> Information Gain = Entropy of Parent - sum (weighted % * Entropy of Child)</b>\n",
    "- <b> Weighted % = Number of observations in particular child/sum (observations in all child nodes)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Gini </b> : \n",
    "- Gini impurity is a measure of misclassification, which applies in a multi-class classifier context. \n",
    "- Gini works similar to entropy, except <b>Gini is quicker to calculate</b>\n",
    "- Where i = Number of classes. The similarity between Gini and entropy is shown in the following figure:\n",
    "\n",
    "![Gini](gini.jpg)\n",
    "\n",
    "![compare](compare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play tennis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D6</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D7</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D8</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D9</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D10</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D11</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D12</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D13</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D14</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Day   Outlook Temperature Humidity    Wind Play tennis\n",
       "0    D1     Sunny         Hot     High    Weak          No\n",
       "1    D2     Sunny         Hot     High  Strong          No\n",
       "2    D3  Overcast         Hot     High    Weak         Yes\n",
       "3    D4      Rain        Mild     High    Weak         Yes\n",
       "4    D5      Rain        Cool   Normal    Weak         Yes\n",
       "5    D6      Rain        Cool   Normal  Strong          No\n",
       "6    D7  Overcast        Cool   Normal  Strong         Yes\n",
       "7    D8     Sunny        Mild     High    Weak          No\n",
       "8    D9     Sunny        Cool   Normal    Weak         Yes\n",
       "9   D10      Rain        Mild   Normal    Weak         Yes\n",
       "10  D11     Sunny        Mild   Normal  Strong         Yes\n",
       "11  D12  Overcast        Mild     High  Strong         Yes\n",
       "12  D13  Overcast         Hot   Normal    Weak         Yes\n",
       "13  D14      Rain        Mild     High  Strong          No"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"DT_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Taking the Humidity variable as an example to classify the Play Tennis field\n",
    "\n",
    "- CHAID: Humidity has two categories and our expected values should be evenly distributed in order to calculate how distinguishing the variable is:\n",
    "\n",
    "![table](tab1.jpg)\n",
    "\n",
    "- Expected is the Average of Play tennis\n",
    "- Differrence is the Play tennis - Expected \n",
    "- Calculating x2 (Chi-square) value:\n",
    "- square of the Difference of Actual - Expected / Expected \n",
    "\n",
    "![chi](chi.jpg)\n",
    "\n",
    "- Calculating degrees of freedom = (r-1) * (c-1)\n",
    "- Where r = number of row components or number of variable categories, C = number of response variables.\n",
    "- Here, there are two row categories (High and Normal) and two column categories (No and Yes).\n",
    "- Hence = (2-1) * (2-1) = 1\n",
    "- p-value for Chi-square 2.8 with 1 d.f = 0.0942\n",
    "- p-value can be obtained with the following Excel formulae: = CHIDIST (2.8, 1) = 0.0942\n",
    "\n",
    "#### In a similar way, we will calculate the p-value for all variables and select the best variable with a low p-value.\n",
    "\n",
    "## $ Entropy = - Σ p * log_2  p $\n",
    "\n",
    "![cal](cal3.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHIDIST\n",
    "- The goodness of fit of a statistical model describes how well it fits a set of observations. Measures of goodness of fit typically summarize the discrepancy between observed values and the values expected under the model in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a similar way, we will calculate information gain for all variables and select the best variable with the highest information gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GINI:\n",
    "\n",
    "$ Gini = 1- Σp^2 $\n",
    "\n",
    "![cal](cal4.jpg)\n",
    "\n",
    "- In a similar way, we will calculate Expected Gini for all variables and select the best with the lowest expected value.\n",
    "- For the purpose of a better understanding, we will also do similar calculations for the Wind variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHAID: \n",
    "Wind has two categories and our expected values should be evenly distributed in order to calculate how distinguishing the variable is:\n",
    "\n",
    "![wind](tab2.jpg)\n",
    "![wind](wind.png)\n",
    "![wind](windcal1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will compare both variables for all three metrics so that we can understand them better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variables</th>\n",
       "      <th>CHAID</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(p-value)</td>\n",
       "      <td>information gain</td>\n",
       "      <td>expected value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Humidity</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.3669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wind</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.4285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>4.066</td>\n",
       "      <td>0.9402</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Better</td>\n",
       "      <td>Low value</td>\n",
       "      <td>High value</td>\n",
       "      <td>Low value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variables      CHAID           Entropy            Gini\n",
       "0          NaN  (p-value)  information gain  expected value\n",
       "1     Humidity     0.0942            0.1518          0.3669\n",
       "2         Wind     0.2733            0.0482          0.4285\n",
       "3  Temperature      4.066            0.9402            0.65\n",
       "4       Better  Low value        High value       Low value"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"compare.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion : The root node is selected by this formula\n",
    "1. CHAID : Select the lowest CHAID\n",
    "2. Entropy : Select the Highest Entropy\n",
    "3. GINI : Select the lowest GINI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For all three calculations, Humidity is proven to be a better classifier than Wind. Hence, we can confirm that all methods convey a similar story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the compare2.xlsx and the formulas to understand the calculations\n",
    "\n",
    "![Diagram](DT_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Root Nodes , Internal Nodes or Split Node or non leaf node  , Leave Nodes \n",
    "![Diagram](DT_4.png)\n",
    "- Decision tree video explaination\n",
    "[![Video](http://img.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg)](https://www.youtube.com/watch?v=7VeUPuFGJHk&t=1s \"Decision tree\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.352px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
