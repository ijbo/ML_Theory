{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How a normal Logistic Regression layers look ? \n",
    "\n",
    "![tittle](Logistic_regression_part2.svg)\n",
    "\n",
    "When we add a Linear and Non Linear layer to the Logistic Regression , it becomes Feed Forward Neural Network.\n",
    "\n",
    "![tittle](FFNN.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"600\"\n",
       "            src=\"https://ml-cheatsheet.readthedocs.io/en/latest/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2b1c1b2a9b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='https://ml-cheatsheet.readthedocs.io/en/latest/', width=1500, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Programming FeedForward NN with MNIST dataset :\n",
    "- Step 1 : Load Dataset\n",
    "    - Split the data into Train\n",
    "    - Split the data into Test\n",
    "    - Display the data \n",
    "- Step 2 : Make Dataset Iterable\n",
    "    - Total Data : 60000\n",
    "    - minibatch : 100\n",
    "    - Iteration : 3000\n",
    "    - Epochs  : **epochs = iterations / (total data / minibatch)** =  3000 / (60000/100) = 5 \n",
    "- Step 3 : Create Model Class \n",
    "- Step 4 : Intanstiate Model Class\n",
    "- Step 5 : Instanstiate Loss Class\n",
    "- Step 6 : Instanstiate Optimizer Class\n",
    "- Step 7 : Train Model\n",
    "   1.   Convert Inputs/labels to variables\n",
    "   -  Clear gradients buffers\n",
    "   -  Get the output given input\n",
    "   -  Get Loss\n",
    "   -  Get Gradeints\n",
    "   -  Update Parameters using gradients\n",
    "   -  Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading MNIST train data set \n",
    "train_dataset =  dsets.MNIST(root=\"./data\",\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading MNIST train data set \n",
    "test_dataset =  dsets.MNIST(root=\"./data\",\n",
    "                            train=False,\n",
    "                            transform=transforms.ToTensor()\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Make Dataset Iterable\n",
    "- Create Train and Test Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset)/batch_size)\n",
    "num_epochs =int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Create Model Class : Build a Feed Forward NN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,num_classes):\n",
    "        super().__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim,hidden_dim)\n",
    "        # Non- Linear function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # Linear function(readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "            # Linear function\n",
    "            out = self.fc1(x)\n",
    "            # Non- Linear function\n",
    "            out = self.sigmoid(out)\n",
    "            # Linear function(readout)\n",
    "            out = self.fc2(out)\n",
    "            \n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Intanstiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dim = size of the image = 28 * 28 = 784 \n",
    "# Output Dim = 10 = predict 10 numbers \n",
    "# Hidden Dim = 100 ,  \n",
    "\n",
    "input_dim =  28*28\n",
    "hidden_dim=100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNN(input_dim,hidden_dim,output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Instanstiate Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion  = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Instanstiate Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "optimizer  = torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.parameters(),len(list(model.parameters())),list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 : Train Model\n",
    "   1.   Convert Inputs/labels to variables\n",
    "   -  Clear gradients buffers\n",
    "   -  Get the output given input, forward pass\n",
    "   -  Get Loss\n",
    "   -  Get Gradeints\n",
    "   -  Update Parameters using gradients\n",
    "   -  Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "# Iterate 5 time \n",
    "for epoch in range (num_epochs):\n",
    "# Loop through all the 60000 images\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        # Load inamges to variable\n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "        #print (\"iter\" , i)\n",
    "        # Reset the gradients \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform Forward pass\n",
    "        output = model(images)\n",
    "        \n",
    "        # Get the loss \n",
    "        loss = criterion(output,labels)\n",
    "    \n",
    "        # Get the gradients \n",
    "        loss.backward()\n",
    "        \n",
    "        # update the parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter +=1\n",
    "        \n",
    "        if iter % 500 == 0 :\n",
    "            # calculate accuracy \n",
    "            correct = 0.\n",
    "            total = 0.\n",
    "            j = 0\n",
    "            for images,labels in test_loader: \n",
    "                images = Variable(images.view(-1,28*28))\n",
    "                output = model(images)\n",
    "                j += 1\n",
    "                print(\"loop\", j )\n",
    "                _,predicted = torch.max(output,1) # returns the max prediction\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "                print(\"correct\",correct)\n",
    "            accuracy = 100 *(correct / total)\n",
    "            print (accuracy)\n",
    "            \n",
    "            #Print loss\n",
    "            print('Iteration: {} . Loss:  {}. Accuracy: {}'.format(iter,loss.data[0],accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tittle](FFNN_2.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
