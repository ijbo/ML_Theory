{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Here we discuss Logistic functions, also understand their use and behaviours. \n",
    "1. Sigmoid \n",
    "2. Softmax\n",
    "\n",
    "#### Multiclass classification : use - Softmax\n",
    "- means a classification task with more than two classes; e.g., classify a set of images of fruits which may be oranges, apples, or pears. \n",
    "- Multiclass classification makes the assumption that each sample is assigned **to one and only one label**: a fruit can be either an apple or a pear but not both at the same time.\n",
    "\n",
    "#### Multilabel classification : use - Sigmoid\n",
    "- assigns to each sample a set of target labels. This can be thought as predicting properties of a data-point that are not mutually exclusive, such as topics that are relevant for a document. A text might be about any of religion, politics, finance or education at the same time or none of these.\n",
    "\n",
    "**Softmax layer is good for multi-class classification while a Sigmoid is good for multi-label.**\n",
    "\n",
    "-**Sigmoid** = Multi-Label Classification Problem = More than one right answer = Non-exclusive outputs (e.g. chest x-rays, hospital admission)\n",
    "\n",
    "-**Softmax** = Multi-Class Classification Problem = Only one right answer = Mutually exclusive outputs (e.g. handwritten digits, irises)\n",
    "\n",
    "![title](sigmoidvssoftmax2-1.png)\n",
    "![title](sigmoidvssoftmax3.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression :\n",
    "- could help us predict the student’s test score on a scale of 0 - 100. \n",
    "- Linear regression predictions are continuous (numbers in a range).\n",
    "\n",
    "#### Logistic Regression  :\n",
    "- could help use predict whether the student passed or failed. \n",
    "- Logistic regression predictions are discrete (only specific values or categories are allowed). \n",
    "- We can also view probability scores underlying the model’s classifications.\n",
    "\n",
    "#### Types of logistic regression\n",
    "- Binary (Pass/Fail)\n",
    "- Multi (Cats, Dogs, Sheep)\n",
    "- Ordinal (Low, Medium, High)\n",
    "- http://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid function :\n",
    "- y = mx + c : linear function\n",
    "- $\\large\\frac {1} {1+e^-y}$ : Logistic function/Sigmoid Function \n",
    "- $\\large\\frac{1} {1+e^-(mx+c)}$  :Subtituting the Linear function into Logistic Function \n",
    "- Passing this into Logictic function we get the Probablity\n",
    "- A sigmoid function can be used in multi-label classification. \n",
    "- The sigmoid function is another logistic function that has a characteristic \"S-curve\", or a smoothed out version of a step function. Sigmoids are often introduced into neural nets to provide non-linearity to the model and are typically used for clustering, pattern classification, and function approximation. \n",
    "- Unlike **softmax** which gives a probability distribution around k classes, **sigmoid** functions allow for independent probabilities. \n",
    "- When looking at a sigmoid function as a neuron in a neural network, input values of a sigmoid neuron can be any value between 0 and 1 and the output is the sigmoid function. \n",
    "- Logistic Sigmoid Function: \n",
    "![title](logistic_regression_schematic.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax Function :\n",
    "- Multi-class Logistic Function \n",
    "\n",
    "##### Softmax : \n",
    "- Softmax is used to calculate the probability distribution of a particular label over k different labels. \n",
    "- Softmax returns a range of 0 to 1 for its outputs with all probabilities equalling 1. \n",
    "- For multi-lables, this will return a probability for each label with the target label having the highest probability. \n",
    "- This is ideal when predicting one label over a set of labels\n",
    "\n",
    "- ![title](softmax_schematic_1.png) \n",
    "\n",
    "- $ P(y=j \\mid z^{(i)}) = \\phi_{softmax}(z^{(i)}) = \\large\\frac{e^{z^{(i)}}}{\\sum_{j=0}^{k} e^{z_{k}^{(i)}}}$\n",
    "\n",
    "- Softmax is an activation function where:\n",
    "    - all of the activations add up to 1\n",
    "    - all of the activations are greater than 0\n",
    "    - all of the activations are less than 1\n",
    "\n",
    "- softmax is equal to  to the activation divided by the sum of  to the activations. That's called softmax.\n",
    "\n",
    "- https://www.youtube.com/watch?v=uQtTwhpv7Ew&feature=youtu.be&t=7395\n",
    "\n",
    "- So when we're doing single label multi-class classification, you generally want softmax as your activation function and you generally want cross-entropy as your loss. Because these things go together in such friendly ways, PyTorch will do them both for you.\n",
    "\n",
    "- Sigmoid and Softmax is that while both give output in [0,1] range, \n",
    "    - Softmax ensures that the <b>sum of outputs</b> along channels (as per specified dimension) is 1 i.e., they are probabilities. \n",
    "    - Sigmoid just makes output between 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy \n",
    "- L : Labels , Actuals\n",
    "- S : Softmax Probablity \n",
    "- cost function/Cross Entropy / log loss  = - L log S - (1 - L) log (1 - S)\n",
    "- CE(S,L) = - L log S - (1 - L) log (1 - S)\n",
    "    - L,S = 0 -> Not Spam\n",
    "    - L,S = 1 -> Spam\n",
    "- Label L = 0 : Not Spam\n",
    "    - -log (1 - S)\n",
    "    - S -> 0 , -log(1-S) is Less +ve (Smaller loss) \n",
    "    - S -> 1 , -log(1-S) is More + ve (Bigger loss)\n",
    "- Label L = 1\n",
    "    - log S\n",
    "    - S -> 0 , -log S is More +ve (Bigger loss)\n",
    "    - S-> 1 ,  -log S is Less +ve (Smaller loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimizing Function :\n",
    "- Goal is to minimize cross entropy loss\n",
    "- Cost Function  = $\\frac{1} {M} \\sum_{i=1}^M CE({mx+c},{Label})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"277px\" version=\"1.1\" width=\"722px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><g transform=\"translate(0.5,0.5)\"><path d=\"M 231 142 L 251 142 L 251 141 L 264.63 141\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 269.88 141 L 262.88 144.5 L 264.63 141 L 262.88 137.5 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 117 94 L 231 94 L 231 189 L 117 189 L 117 166.5 L 101 166.5 L 101 154.5 L 117 154.5 L 117 128.5 L 101 128.5 L 101 116.5 L 117 116.5 Z\" fill=\"#cccccc\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 117 116.5 L 133 116.5 L 133 128.5 L 117 128.5 M 117 154.5 L 133 154.5 L 133 166.5 L 117 166.5\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><g fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\"><text x=\"138.5\" y=\"145\">Linear Function</text></g><path d=\"M 81 136 L 104.63 136\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 109.88 136 L 102.88 139.5 L 104.63 136 L 102.88 132.5 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><rect fill=\"#ffe599\" height=\"270\" pointer-events=\"none\" rx=\"4.8\" ry=\"4.8\" stroke=\"#000000\" stroke-width=\"2\" width=\"80\" x=\"1\" y=\"1\"/><g transform=\"translate(33.5,17.5)\"><switch><foreignObject height=\"236\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"13\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 15px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div>0<div>1</div><div>2</div><div>3</div><div>4</div><div>5</div><div>6</div><div>7</div><div>8</div><div>9</div><div>10</div><div>11</div></div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"7\" y=\"124\">[Not supported by viewer]</text></switch></g><g transform=\"translate(27.5,64.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"26\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 28px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">Input</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"13\" y=\"12\">Input</text></switch></g><g transform=\"translate(36.5,34.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"8\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 10px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">X</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"4\" y=\"12\">X</text></switch></g><g transform=\"translate(119.5,199.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"87\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 87px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">y_pred = mx +c </div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"44\" y=\"12\">y_pred = mx +c&amp;nbsp;</text></switch></g><path d=\"M 351 141 L 454.63 141\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 459.88 141 L 452.88 144.5 L 454.63 141 L 452.88 137.5 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><rect fill=\"#ccff99\" height=\"270\" pointer-events=\"none\" rx=\"4.8\" ry=\"4.8\" stroke=\"#000000\" stroke-width=\"2\" width=\"80\" x=\"271\" y=\"6\"/><g transform=\"translate(292.5,69.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"37\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 37px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">Output</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"19\" y=\"12\">Output</text></switch></g><g transform=\"translate(306.5,24.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"8\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 10px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">Y</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"4\" y=\"12\">Y</text></switch></g><path d=\"M 541 141 L 634.63 141\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 639.88 141 L 632.88 144.5 L 634.63 141 L 632.88 137.5 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><rect fill=\"#ff9999\" height=\"270\" pointer-events=\"none\" rx=\"4.8\" ry=\"4.8\" stroke=\"#000000\" stroke-width=\"2\" width=\"80\" x=\"461\" y=\"6\"/><rect fill=\"#b3b3b3\" height=\"40\" pointer-events=\"none\" rx=\"6\" ry=\"6\" stroke=\"#000000\" width=\"80\" x=\"371\" y=\"151\"/><g transform=\"translate(372.5,157.5)\"><switch><foreignObject height=\"26\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"76\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 76px; white-space: normal; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">Logistic Function</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"38\" y=\"19\">Logistic Function</text></switch></g><g transform=\"translate(478.5,24.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"45\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 45px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">Softmax</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"23\" y=\"12\">Softmax</text></switch></g><rect fill=\"#66b2ff\" height=\"270\" pointer-events=\"none\" rx=\"4.8\" ry=\"4.8\" stroke=\"#000000\" stroke-width=\"2\" width=\"80\" x=\"641\" y=\"6\"/><g transform=\"translate(659.5,20.5)\"><switch><foreignObject height=\"40\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"52\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 52px; white-space: normal; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">Y_Actual <div>True Labels</div></div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"26\" y=\"26\">[Not supported by viewer]</text></switch></g><rect fill=\"#999999\" height=\"40\" pointer-events=\"none\" rx=\"6\" ry=\"6\" stroke=\"#000000\" width=\"80\" x=\"551\" y=\"151\"/><g transform=\"translate(569.5,157.5)\"><switch><foreignObject height=\"26\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"42\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 42px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">Cross <div>Entropy</div></div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"21\" y=\"19\">[Not supported by viewer]</text></switch></g><g transform=\"translate(491.5,114.5)rotate(-1,10,34)\"><switch><foreignObject height=\"68\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"20\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 22px; white-space: nowrap; overflow-wrap: normal; font-weight: bold; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">[0.1<div>0.1</div><div>.....</div><div>0.4,</div><div>0.4]</div></div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" font-weight=\"bold\" text-anchor=\"middle\" x=\"10\" y=\"40\">[Not supported by viewer]</text></switch></g><g transform=\"translate(298.5,137.5)\"><switch><foreignObject height=\"96\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"24\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 24px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">0.9<div>1.2</div><div>.</div><div>.</div><div>.</div><div>.</div><div>21.5</div></div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"12\" y=\"54\">[Not supported by viewer]</text></switch></g><g transform=\"translate(673.5,114.5)\"><switch><foreignObject height=\"68\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"14\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 14px; white-space: nowrap; overflow-wrap: normal; font-weight: bold; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">0,<div><b>0,</b></div><div>....</div><div><b>1,</b></div><div>1</div></div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" font-weight=\"bold\" text-anchor=\"middle\" x=\"7\" y=\"40\">[Not supported by viewer]</text></switch></g></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import SVG, display\n",
    "def show_svg():\n",
    "    display(SVG('Logistic_regression.svg'))\n",
    "\n",
    "show_svg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Programming Logistic regression with MNIST dataset :\n",
    "- Step 1 : Load Dataset\n",
    "    - Split the data into Train\n",
    "    - Split the data into Test\n",
    "    - Display the data \n",
    "- Step 2 : Make Dataset Iterable\n",
    "    - Total Data : 60000\n",
    "    - minibatch : 100\n",
    "    - Iteration : 3000\n",
    "    - Epochs  : **epochs = iterations / (total data / minibatch)** =  3000 / (60000/100) = 5 \n",
    "- Step 3 : Create Model Class \n",
    "- Step 4 : Intanstiate Model Class\n",
    "- Step 5 : Instanstiate Loss Class\n",
    "- Step 6 : Instanstiate Optimizer Class\n",
    "- Step 7 : Train Model\n",
    "   1.   Convert Inputs/labels to variables\n",
    "   -  Clear gradients buffers\n",
    "   -  Get the output given input\n",
    "   -  Get Loss\n",
    "   -  Get Gradeints\n",
    "   -  Update Parameters using gradients\n",
    "   -  Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading MNIST data set \n",
    "train_dataset =  dsets.MNIST(root=\"./data\",\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,\n",
       " ['0 - zero',\n",
       "  '1 - one',\n",
       "  '2 - two',\n",
       "  '3 - three',\n",
       "  '4 - four',\n",
       "  '5 - five',\n",
       "  '6 - six',\n",
       "  '7 - seven',\n",
       "  '8 - eight',\n",
       "  '9 - nine'],\n",
       " tuple,\n",
       " tuple)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset),train_dataset.classes,type(train_dataset[0]),type(train_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input matrix\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the Dataset \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image = train_dataset[0][0].numpy().reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24df95086a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset =  dsets.MNIST(root=\"./data\",\n",
    "                            train=False,\n",
    "                            transform=transforms.ToTensor()\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,\n",
       " ['0 - zero',\n",
       "  '1 - one',\n",
       "  '2 - two',\n",
       "  '3 - three',\n",
       "  '4 - four',\n",
       "  '5 - five',\n",
       "  '6 - six',\n",
       "  '7 - seven',\n",
       "  '8 - eight',\n",
       "  '9 - nine'],\n",
       " tuple,\n",
       " tuple)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset),test_dataset.classes,type(test_dataset[0]),type(test_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image = test_dataset[0][0].numpy().reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24df9d461d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_image,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset)/batch_size)\n",
    "num_epochs =int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ML\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data can be iterated \n",
    "import collections\n",
    "isinstance(train_loader,collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(test_loader,collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Create Model Class : Build a Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.Linear = nn.Linear(input_dim,output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "            out = self.Linear(x)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Intanstiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dim = size of the image = 28 * 28 = 784 \n",
    "# Output Dim = 10 = predict 10 numbers \n",
    "input_dim =  28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LinearRegressionModel(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Instanstiate Loss Class\n",
    "\n",
    "- Since we are using crossentropy loss the Linear function gets converted to logistic function , softmax is inherited in the CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion  = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Instanstiate Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "optimizer  = torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<generator object Module.parameters at 0x0000024DF74AC750>,\n",
       " 2,\n",
       " [Parameter containing:\n",
       "  tensor([[-6.2775e-05, -1.7992e-02, -1.4125e-02,  ...,  3.4856e-02,\n",
       "            2.1087e-02,  3.4633e-02],\n",
       "          [ 2.8196e-02,  9.6199e-03, -3.3445e-02,  ..., -2.8764e-03,\n",
       "           -3.2032e-02,  2.5530e-02],\n",
       "          [ 1.1177e-03, -2.0589e-02, -3.3777e-03,  ..., -3.9267e-03,\n",
       "           -1.4245e-02,  2.5070e-02],\n",
       "          ...,\n",
       "          [ 2.0845e-03,  3.4076e-02,  3.0595e-02,  ...,  2.9534e-02,\n",
       "           -3.0536e-02,  1.5214e-02],\n",
       "          [-1.3312e-02, -2.2213e-02, -3.0292e-02,  ..., -1.9818e-02,\n",
       "           -2.1504e-02, -1.4282e-03],\n",
       "          [-1.0623e-02,  3.3806e-02,  2.8494e-02,  ..., -2.1546e-02,\n",
       "            2.2427e-02, -3.5479e-02]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0236, -0.0067,  0.0137,  0.0334,  0.0296,  0.0232, -0.0256, -0.0336,\n",
       "          -0.0192,  0.0036], requires_grad=True)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters(),len(list(model.parameters())),list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 784]), torch.Size([10]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0].size(),list(model.parameters())[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Logistic_regression_part2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 : Train Model\n",
    "   1.   Convert Inputs/labels to variables\n",
    "   -  Clear gradients buffers\n",
    "   -  Get the output given input, forward pass\n",
    "   -  Get Loss\n",
    "   -  Get Gradeints\n",
    "   -  Update Parameters using gradients\n",
    "   -  Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "iter = 0\n",
    "# Iterate 5 time \n",
    "for epoch in range (num_epochs):\n",
    "# Loop through all the 60000 images\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        # Load inamges to variable\n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "        #print (\"iter\" , i)\n",
    "        # Reset the gradients \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform Forward pass\n",
    "        output = model(images)\n",
    "        \n",
    "        # Get the loss \n",
    "        loss = criterion(output,labels)\n",
    "    \n",
    "        # Get the gradients \n",
    "        loss.backward()\n",
    "        \n",
    "        # update the parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter +=1\n",
    "        \n",
    "        if iter % 500 == 0 :\n",
    "            # calculate accuracy \n",
    "            correct = 0.\n",
    "            total = 0.\n",
    "            j = 0\n",
    "            for images,labels in test_loader: \n",
    "                images = Variable(images.view(-1,28*28))\n",
    "                output = model(images)\n",
    "                j += 1\n",
    "                print(\"loop\", j )\n",
    "                _,predicted = torch.max(output,1) # returns the max prediction\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "                print(\"correct\",correct)\n",
    "            accuracy = 100 *(correct / total)\n",
    "            print (accuracy)\n",
    "            \n",
    "            #Print loss\n",
    "            print('Iteration: {} . Loss:  {}. Accuracy: {}'.format(iter,loss.data[0],accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand : Logistic regression  : https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html#binary-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
