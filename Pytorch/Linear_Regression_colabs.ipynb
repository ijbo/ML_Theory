{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6niBjBI0jav7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRFPJCmukRte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAt_ecyJksES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_values = [i for i in range(11)]\n",
        "x_train = np.array(x_values, dtype=np.float32)\n",
        "x_train = x_train.reshape(-1, 1)\n",
        "\n",
        "y_values = [2*i + 1 for i in x_values]\n",
        "y_train = np.array(y_values, dtype=np.float32)\n",
        "y_train = y_train.reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chY0pqgGk5ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "CREATE MODEL CLASS\n",
        "'''\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp08J94yk52G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 1\n",
        "output_dim = 1\n",
        "\n",
        "model = LinearRegressionModel(input_dim, output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g26pyYVGk545",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################\n",
        "#  USE GPU FOR MODEL  #\n",
        "#######################\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N7_prpyk57i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yemq7q3tk59z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCeALc3GlUjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    epoch += 1\n",
        "    # Convert numpy array to torch Variable\n",
        "\n",
        "    #######################\n",
        "    #  USE GPU FOR MODEL  #\n",
        "    #######################\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
        "\n",
        "    #######################\n",
        "    #  USE GPU FOR MODEL  #\n",
        "    #######################\n",
        "    if torch.cuda.is_available():\n",
        "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
        "        \n",
        "    # Clear gradients w.r.t. parameters\n",
        "    optimizer.zero_grad() \n",
        "    \n",
        "    # Forward to get output\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Calculate Loss\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    # Getting gradients w.r.t. parameters\n",
        "    loss.backward()\n",
        "    \n",
        "    # Updating parameters\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Logging\n",
        "    print('epoch {}, loss {}'.format(epoch, loss.data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG3T1wbdmlEW",
        "colab_type": "code",
        "outputId": "5e09d5b8-29ea-419e-d1c9-2f8837bda867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def print_graph(g, level=0):\n",
        "    if g == None: return\n",
        "    print('#'*level*1, g)\n",
        "    for subg in g.next_functions:\n",
        "        #print(subg)\n",
        "        print_graph(subg[0], level+1)\n",
        "\n",
        "print_graph(loss.grad_fn, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# <MseLossBackward object at 0x7f540267e198>\n",
            "## <AddmmBackward object at 0x7f5404aabf98>\n",
            "### <AccumulateGrad object at 0x7f540267e390>\n",
            "### <TBackward object at 0x7f540267e3c8>\n",
            "#### <AccumulateGrad object at 0x7f540267e400>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}