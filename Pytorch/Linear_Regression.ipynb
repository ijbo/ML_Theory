{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1\n",
    "#### <b> Hypothesis: </b> y_pred = mx +  b \n",
    "#### <b> Parameters : </b> m (coefficient,slope, gradient , weights) , b (Bias , intercept)\n",
    "\n",
    "#### <b> Actual function : </b> y_actual= 2x + 1 \n",
    "#### <b> Parameters : </b> 2 (coefficient,slope, gradient , weights) , 1 (Bias , intercept)\n",
    "\n",
    "#### <b> Minimize :</b> the distance y_pred and y_actual "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 \n",
    "#### Lets create a data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values = [ i for i in range(11)]\n",
    "x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "x_train = np.array(x_values,dtype=np.float32)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 d Array\n",
    "x_train = x_train.reshape(11,1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Actual function : y_actual= 2x + 1 \n",
    "y_value = [ 2*i+1 for i in x_values]\n",
    "y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_value,dtype=np.float32)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=y_train.reshape(11,1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn ## require to build a linear regression model \n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 : Create a Model\n",
    "#Building our Model\n",
    "# Create class\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__ (self,input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.Linear = nn.Linear(input_dim,output_dim) # this means y=mx + 1 \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.Linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2 :  Intantiate a model\n",
    "input_dim = 1 \n",
    "output_dim = 1 \n",
    "model  = LinearRegressionModel(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3 : Intantiate a loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4 : Intantiate a optimizer class : paramenets = parameters - learning_rate * parameter_gradients\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer =  torch.optim.SGD(model.parameters(),learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4359]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.2194], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 ,  loss : 7.979703514138237e-05\n",
      "epoch : 2 ,  loss : 7.890591223258525e-05\n",
      "epoch : 3 ,  loss : 7.802664185874164e-05\n",
      "epoch : 4 ,  loss : 7.715288666076958e-05\n",
      "epoch : 5 ,  loss : 7.628850289620459e-05\n",
      "epoch : 6 ,  loss : 7.543867104686797e-05\n",
      "epoch : 7 ,  loss : 7.459903281414881e-05\n",
      "epoch : 8 ,  loss : 7.376360736088827e-05\n",
      "epoch : 9 ,  loss : 7.294161332538351e-05\n",
      "epoch : 10 ,  loss : 7.213030767161399e-05\n",
      "epoch : 11 ,  loss : 7.132146129151806e-05\n",
      "epoch : 12 ,  loss : 7.052611908875406e-05\n",
      "epoch : 13 ,  loss : 6.973954441491514e-05\n",
      "epoch : 14 ,  loss : 6.896247214172035e-05\n",
      "epoch : 15 ,  loss : 6.818737892899662e-05\n",
      "epoch : 16 ,  loss : 6.742563709849492e-05\n",
      "epoch : 17 ,  loss : 6.667605339316651e-05\n",
      "epoch : 18 ,  loss : 6.592811405425891e-05\n",
      "epoch : 19 ,  loss : 6.519364251289517e-05\n",
      "epoch : 20 ,  loss : 6.446345651056617e-05\n",
      "epoch : 21 ,  loss : 6.374248914653435e-05\n",
      "epoch : 22 ,  loss : 6.303205009317026e-05\n",
      "epoch : 23 ,  loss : 6.232885789358988e-05\n",
      "epoch : 24 ,  loss : 6.163465877762064e-05\n",
      "epoch : 25 ,  loss : 6.094332638895139e-05\n",
      "epoch : 26 ,  loss : 6.0263730119913816e-05\n",
      "epoch : 27 ,  loss : 5.9592872275970876e-05\n",
      "epoch : 28 ,  loss : 5.892527406103909e-05\n",
      "epoch : 29 ,  loss : 5.826545748277567e-05\n",
      "epoch : 30 ,  loss : 5.7615325204096735e-05\n",
      "epoch : 31 ,  loss : 5.6973349273903295e-05\n",
      "epoch : 32 ,  loss : 5.6334978580707684e-05\n",
      "epoch : 33 ,  loss : 5.571074871113524e-05\n",
      "epoch : 34 ,  loss : 5.508908361662179e-05\n",
      "epoch : 35 ,  loss : 5.447123112389818e-05\n",
      "epoch : 36 ,  loss : 5.386421617004089e-05\n",
      "epoch : 37 ,  loss : 5.326300743035972e-05\n",
      "epoch : 38 ,  loss : 5.2665949624497443e-05\n",
      "epoch : 39 ,  loss : 5.20786561537534e-05\n",
      "epoch : 40 ,  loss : 5.1499031542334706e-05\n",
      "epoch : 41 ,  loss : 5.092363790026866e-05\n",
      "epoch : 42 ,  loss : 5.035189678892493e-05\n",
      "epoch : 43 ,  loss : 4.9789978220360354e-05\n",
      "epoch : 44 ,  loss : 4.9236627091886476e-05\n",
      "epoch : 45 ,  loss : 4.8689420509617776e-05\n",
      "epoch : 46 ,  loss : 4.8142366722458974e-05\n",
      "epoch : 47 ,  loss : 4.760459341923706e-05\n",
      "epoch : 48 ,  loss : 4.7072942834347486e-05\n",
      "epoch : 49 ,  loss : 4.6549681428587064e-05\n",
      "epoch : 50 ,  loss : 4.602743138093501e-05\n",
      "epoch : 51 ,  loss : 4.551307574729435e-05\n",
      "epoch : 52 ,  loss : 4.500496288528666e-05\n",
      "epoch : 53 ,  loss : 4.4501706724986434e-05\n",
      "epoch : 54 ,  loss : 4.40071162302047e-05\n",
      "epoch : 55 ,  loss : 4.351598545326851e-05\n",
      "epoch : 56 ,  loss : 4.302638990338892e-05\n",
      "epoch : 57 ,  loss : 4.254708983353339e-05\n",
      "epoch : 58 ,  loss : 4.207151505397633e-05\n",
      "epoch : 59 ,  loss : 4.160282696830109e-05\n",
      "epoch : 60 ,  loss : 4.113839895580895e-05\n",
      "epoch : 61 ,  loss : 4.06831968575716e-05\n",
      "epoch : 62 ,  loss : 4.022897337563336e-05\n",
      "epoch : 63 ,  loss : 3.9775077311787754e-05\n",
      "epoch : 64 ,  loss : 3.933342304662801e-05\n",
      "epoch : 65 ,  loss : 3.889203435392119e-05\n",
      "epoch : 66 ,  loss : 3.846108302241191e-05\n",
      "epoch : 67 ,  loss : 3.802956416620873e-05\n",
      "epoch : 68 ,  loss : 3.760495746973902e-05\n",
      "epoch : 69 ,  loss : 3.718210427905433e-05\n",
      "epoch : 70 ,  loss : 3.676888081827201e-05\n",
      "epoch : 71 ,  loss : 3.63581748388242e-05\n",
      "epoch : 72 ,  loss : 3.595182715798728e-05\n",
      "epoch : 73 ,  loss : 3.554981594788842e-05\n",
      "epoch : 74 ,  loss : 3.515393837005831e-05\n",
      "epoch : 75 ,  loss : 3.476258279988542e-05\n",
      "epoch : 76 ,  loss : 3.43722895195242e-05\n",
      "epoch : 77 ,  loss : 3.398949047550559e-05\n",
      "epoch : 78 ,  loss : 3.3610736863920465e-05\n",
      "epoch : 79 ,  loss : 3.323280543554574e-05\n",
      "epoch : 80 ,  loss : 3.286463470431045e-05\n",
      "epoch : 81 ,  loss : 3.2495408959221095e-05\n",
      "epoch : 82 ,  loss : 3.2131370971910655e-05\n",
      "epoch : 83 ,  loss : 3.1771938665769994e-05\n",
      "epoch : 84 ,  loss : 3.141846173093654e-05\n",
      "epoch : 85 ,  loss : 3.1067444069776684e-05\n",
      "epoch : 86 ,  loss : 3.0722345400135964e-05\n",
      "epoch : 87 ,  loss : 3.0376826543943025e-05\n",
      "epoch : 88 ,  loss : 3.004025165864732e-05\n",
      "epoch : 89 ,  loss : 2.9705886845476925e-05\n",
      "epoch : 90 ,  loss : 2.9374110454227775e-05\n",
      "epoch : 91 ,  loss : 2.9041630114079453e-05\n",
      "epoch : 92 ,  loss : 2.8720074624288827e-05\n",
      "epoch : 93 ,  loss : 2.8396660127327777e-05\n",
      "epoch : 94 ,  loss : 2.8082087737857364e-05\n",
      "epoch : 95 ,  loss : 2.776747351163067e-05\n",
      "epoch : 96 ,  loss : 2.745844903984107e-05\n",
      "epoch : 97 ,  loss : 2.715279333642684e-05\n",
      "epoch : 98 ,  loss : 2.684932405827567e-05\n",
      "epoch : 99 ,  loss : 2.6551068003755063e-05\n",
      "epoch : 100 ,  loss : 2.625212073326111e-05\n"
     ]
    }
   ],
   "source": [
    "# Step 5 : Train The model \n",
    "for epoch in range(epochs):\n",
    "    epoch += 1 \n",
    "    #convert numpy array to torch Variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    labels = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "    #clear the gradients \n",
    "    optimizer.zero_grad() # dont want to the gradients from previous epoch\n",
    "    \n",
    "    #get output \n",
    "    output = model(inputs)\n",
    "    \n",
    "    #calculate loss #scalar loss\n",
    "    loss = criterion(output,labels)\n",
    "    \n",
    "    #getting gradients \n",
    "    loss.backward()\n",
    "    \n",
    "    #updating parameters \n",
    "    optimizer.step()\n",
    "    \n",
    "    print('epoch : {} ,  loss : {}'.format(epoch,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7231588],\n",
       "       [ 2.7630265],\n",
       "       [ 4.802894 ],\n",
       "       [ 6.842762 ],\n",
       "       [ 8.882629 ],\n",
       "       [10.922497 ],\n",
       "       [12.962365 ],\n",
       "       [15.002233 ],\n",
       "       [17.042099 ],\n",
       "       [19.081966 ],\n",
       "       [21.121834 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99046886],\n",
       "       [ 2.9918413 ],\n",
       "       [ 4.993214  ],\n",
       "       [ 6.994587  ],\n",
       "       [ 8.995959  ],\n",
       "       [10.997332  ],\n",
       "       [12.998705  ],\n",
       "       [15.000077  ],\n",
       "       [17.00145   ],\n",
       "       [19.002823  ],\n",
       "       [21.004194  ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model\n",
    "save_model = False\n",
    "if save_model is True :\n",
    "    torch.save(model.state_dict(),'model_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_model\n",
    "load_model = False\n",
    "if load_model is True :\n",
    "    torch.load_state_dict(torch.load('model_lr.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[2.0399]], requires_grad=True), Parameter containing:\n",
       " tensor([0.7232], requires_grad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[2.0014]], requires_grad=True), Parameter containing:\n",
       " tensor([0.9905], requires_grad=True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and Variables on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Linear??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
